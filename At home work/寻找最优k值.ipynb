{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "        knn = self.nearest[:, 1]  \n",
    "        return self.nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "#from sklearn.model_selection import KFold\n",
    "#kf=KFold(n_splits=10)\n",
    "def run(df):\n",
    "    data=np.array(df)\n",
    "    data2=np.array(df.drop('label',axis=1))\n",
    "    rate=0.1\n",
    "    dmax=[]\n",
    "    for m in range(0,len(data2)-1):\n",
    "        for n in range(m+1,len(data2)):\n",
    "            dmax.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "    a = np.percentile(dmax,10) #密度阈值(%10分位数)\n",
    "    F1=[]\n",
    "    for k in range(1,21):\n",
    "        x1 = np.array([[1,1],[1,-1]])\n",
    "        x2 = np.array([1,np.floor(k / 3)/ k])\n",
    "        (Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "        H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "        Dn,Dn_filted= [],[]\n",
    "        noise_set=pd.DataFrame(columns=df.columns)\n",
    "        label_set=list(set(df.label))\n",
    "        for r in label_set:    \n",
    "            noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False)]) #选取噪声比例 \n",
    "        data_cut=df[~df.index.isin(noise_set.index)]\n",
    "        no=[]\n",
    "        for j in range(0,len(noise_set)):\n",
    "            no.append(np.random.choice(label_set))\n",
    "        noise_set['label2']=no\n",
    "        noise_set.reset_index(drop=True,inplace=True)\n",
    "        for l in range(0,len(noise_set)):  #随机替换标签\n",
    "            label_set=list(set(df.label))\n",
    "            if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "                label_set.remove(noise_set.loc[l,'label'])\n",
    "                noise_set.loc[l,'label2']=np.random.choice(label_set) #从剩余列表中随机选择\n",
    "        noise=noise_set.drop(['label'],axis=1)\n",
    "        noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "        data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "        data=np.array(data)\n",
    "        kdt = KdTree()\n",
    "        kdt.create(data)  \n",
    "        for x in data:\n",
    "            near= kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "            density = 0\n",
    "            t,hon,hen,dist_hon,dist_hen,DoD,DRL= 0,0,0,0,0,0,0\n",
    "            for i in range(1,k+1):\n",
    "                if x[-1] == near[i][1].data[-1]:\n",
    "                    t += 1\n",
    "                    hon += 1\n",
    "                    dist_hon += near[i][0]\n",
    "                else:\n",
    "                    hen += 1\n",
    "                    dist_hen += near[i][0]\n",
    "                density += near[i][0]  #密度   \n",
    "            DoD = abs(dist_hen - dist_hon) #相异性差值(要加绝对值)\n",
    "            DRL = (hen - hon)  #标签异同差   \n",
    "            Ps = t / k\n",
    "            Pd = 1 - Ps\n",
    "            if (Ps==1)|(Ps==0):\n",
    "                H = 0\n",
    "            else:\n",
    "                H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "          #  print('densit:',density)\n",
    "            if (density <= a): #高密度区域\n",
    "                #rint('高密度区')\n",
    "                if DRL > 0:\n",
    "                    Dn.append(list(x))\n",
    "                   #print('高密度区噪声')\n",
    "            else:\n",
    "                if (H < H_): #低密度单一标签区域\n",
    "                    if DRL > 0:\n",
    "                        Dn.append(list(x))\n",
    "                else: #低密度混合标签区域\n",
    "                    DoD_ = density / k\n",
    "                    if DoD >= DoD_:\n",
    "                        train_hon,train_hen=[],[]\n",
    "                        for j in data:\n",
    "                            if j[-1]==x[-1]:\n",
    "                                train_hon.append(j)\n",
    "                            else:\n",
    "                                train_hen.append(j)\n",
    "                        train_prositive=np.array(train_hon)\n",
    "                        train_negetive=np.array(train_hen)\n",
    "                        kdt_hon=KdTree()\n",
    "                        kdt_hen=KdTree()\n",
    "                        kdt_hon.create(train_prositive)\n",
    "                        kdt_hen.create(train_negetive)\n",
    "                        near_hon=kdt_hon.search(x[:-1],k+1)\n",
    "                        near_hen=kdt_hen.search(x[:-1],k)\n",
    "                        dist_hon,dist_hen = 0,0\n",
    "                        for n in near_hon:\n",
    "                            dist_hon += n[0]\n",
    "                        for n in near_hen:\n",
    "                            dist_hen += n[0]\n",
    "                        if (dist_hon ) / (dist_hen ) > 1.0:\n",
    "                            Dn.append(list(x))\n",
    "        noise_neighbor=[]                   \n",
    "        for e in Dn:  # 计算噪声分数\n",
    "            e=np.array(e)\n",
    "            near2=kdt.search(e[:-1],k+1) #k近邻\n",
    "            for i in range(1,k+1):\n",
    "                noise_neighbor.append(list(near2[i][1].data))\n",
    "        for e in Dn:\n",
    "            e=np.array(e)\n",
    "            near3=kdt.search(e[:-1],k+1)\n",
    "            t_e=noise_neighbor.count(list(e)) #处于其它噪声近邻的次数\n",
    "            confidence_e= 1 / np.sqrt(1+t_e*t_e)#e的置信度\n",
    "            neighborhood_e=0\n",
    "            for i in range(1,k+1):\n",
    "                t_ei=noise_neighbor.count(list(near3[i][1].data))\n",
    "                confidence_ei=1 / np.sqrt(1+t_ei*t_ei) \n",
    "                if near3[i][1].data[-1]==e[-1]:\n",
    "                    different_class=-1\n",
    "                else:\n",
    "                    different_class=1\n",
    "                if list(near3[i][1].data) in Dn: \n",
    "                    isnoise=1\n",
    "                else:\n",
    "                    isnoise=-1\n",
    "                near4=kdt.search(near3[i][1].data[:-1],k+1)\n",
    "                n_ei=0\n",
    "                for j in range(1,k+1):\n",
    "                    if list(near4[j][1].data) in Dn:\n",
    "                        n_ei += 1\n",
    "                clean_ei= (k + isnoise*(n_ei-k)) / (2*k) #纯净度\n",
    "                neighborhood_e += (clean_ei*confidence_ei*different_class)/k \n",
    "            NS_e=confidence_e * neighborhood_e #噪声得分\n",
    "            if NS_e > 0:\n",
    "                Dn_filted.append(list(e))  \n",
    "\n",
    "        noise_list=noise.values.tolist()\n",
    "        TP = 0\n",
    "        for c in Dn_filted:\n",
    "            if c in noise_list:\n",
    "                TP += 1\n",
    "        FP = len(Dn_filted) - TP\n",
    "        FN = len(noise_list) - TP\n",
    "        precision= TP / (TP + FP)\n",
    "        recall= TP / (TP + FN)\n",
    "        f1=2 * (precision * recall) / (precision + recall) \n",
    "        F1.append(f1)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#鸢尾花数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_sample = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_sample = pd.DataFrame(min_max_scaler.fit_transform(np.array(iris_sample)))\n",
    "iris_sample['label'] = iris.target\n",
    "iris_F1=run(iris_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#红酒数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_wine\n",
    "wine= load_wine()\n",
    "wine_sample = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_sample = pd.DataFrame(min_max_scaler.fit_transform(np.array(wine_sample)))\n",
    "wine_sample['label'] = wine.target\n",
    "wine_F1=run(wine_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#种子数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seeds=pd.read_csv('C:/Users/liu/python works/mydata/seeds.csv',engine='python')\n",
    "seeds_sample=seeds.drop(['label'],axis=1)\n",
    "seeds_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(seeds_sample)))\n",
    "seeds_sample['label']=seeds.label\n",
    "seeds_F1=run(seeds_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#glass数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "glass=pd.read_csv('C:/Users/liu/python works/mydata/glass.csv',engine='python')\n",
    "glass_sample=glass.drop(['label'],axis=1)\n",
    "glass_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(glass_sample)))\n",
    "glass_sample['label']=glass.label\n",
    "glass_F1=run(glass_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#蛋白质定位点数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ecoli=pd.read_csv('C:/Users/liu/python works/mydata/ecoli.csv',engine='python')\n",
    "ecoli_sample=ecoli.drop(['label'],axis=1)\n",
    "ecoli_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(ecoli_sample)))\n",
    "ecoli_sample['label']=ecoli.label\n",
    "ecoli_F1=run(ecoli_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#图像分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 54min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image=pd.read_csv('C:/Users/liu/python works/mydata/segmentation.csv')\n",
    "image_sample=image.drop(['label'],axis=1)\n",
    "image_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(image_sample)))\n",
    "image_sample['label']=image.label\n",
    "image_F1=run(image_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7064516129032259,\n",
       " 0.8492063492063492,\n",
       " 0.8231046931407943,\n",
       " 0.8674242424242425,\n",
       " 0.823956442831216,\n",
       " 0.8312159709618875,\n",
       " 0.822463768115942,\n",
       " 0.8333333333333333,\n",
       " 0.8214285714285715,\n",
       " 0.8220640569395018,\n",
       " 0.8000000000000002,\n",
       " 0.8021015761821367,\n",
       " 0.7972027972027971,\n",
       " 0.8172043010752688,\n",
       " 0.81195079086116,\n",
       " 0.7747440273037542,\n",
       " 0.776271186440678,\n",
       " 0.7937608318890815,\n",
       " 0.7796610169491526,\n",
       " 0.7697478991596638]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#汽车数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "statlog=pd.read_csv('C:/Users/liu/python works/mydata/statlog.csv',engine='python')\n",
    "statlog_sample=statlog.drop('label',axis=1)\n",
    "statlog_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(statlog_sample)))\n",
    "statlog_sample['label']=statlog.label  \n",
    "statlog_F1=run(statlog_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 6min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yeast=pd.read_csv('C:/Users/liu/python works/mydata/yeast.csv',engine='python')\n",
    "yeast_sample=yeast.drop(['label'],axis=1)\n",
    "yeast_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(yeast_sample)))\n",
    "yeast_sample['label']=yeast.label\n",
    "yeast_F1=run(yeast_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#字母数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 24min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "letter=pd.read_csv('C:/Users/liu/python works/mydata/letter.csv')\n",
    "letter_sample=letter.drop(['label'],axis=1)\n",
    "letter_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(letter_sample)))\n",
    "letter_sample['label']=letter.label\n",
    "letter_F1=run(letter_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#thyroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "thyroid=pd.read_csv('C:/Users/liu/python works/mydata/new-thyroid.csv',engine='python')\n",
    "thyroid_sample=thyroid.drop(['label'],axis=1)\n",
    "thyroid_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(thyroid_sample)))\n",
    "thyroid_sample['label']=thyroid.label\n",
    "thyroid_F1=run(thyroid_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vowel=pd.read_csv('C:/Users/liu/python works/mydata/vowel.csv',engine='python')\n",
    "vowel_sample=vowel.drop(['label'],axis=1)\n",
    "vowel_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(vowel_sample)))\n",
    "vowel_sample['label']=vowel.label\n",
    "vowel_F1=run(vowel_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 41min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pen_base=pd.read_csv('C:/Users/liu/python works/mydata/pen_base.csv',engine='python')\n",
    "pen_sample=pen_base.drop(['label'],axis=1)\n",
    "pen_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(pen_sample)))\n",
    "pen_sample['label']=pen_base.label\n",
    "pen_F1=run(pen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "k_value=range(1,21)\n",
    "plt.xticks([2,4,6,8,10,12,14,16,18,20],['2','4','6','8','10','12','14','16','18','20'])\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0],['0.2','0.4','0.6','0.8','1.0'])\n",
    "plt.plot(k_value,iris_F1,'r-',label='Iris')\n",
    "plt.plot(k_value,wine_F1,'g-',label='Wine')\n",
    "plt.plot(k_value,seeds_F1,'b-',label='Seeds')\n",
    "plt.plot(k_value,thyroid_F1,'y-',label='Thyroid')\n",
    "plt.plot(k_value,statlog_F1,'c-',label='Statlog')\n",
    "plt.plot(k_value,ecoli_F1,'m-',label='Ecoli')\n",
    "plt.plot(k_value,glass_F1,'k-',label='Glass')\n",
    "plt.plot(k_value,image_F1,'-',color='brown',label='Image')\n",
    "plt.plot(k_value,letter_F1,'-',color='orange',label='Letter')\n",
    "plt.plot(k_value,yeast_F1,'-',color='peru',label='Yeast')\n",
    "plt.plot(k_value,pen_F1,'-',color='darkblue',label='Pen')\n",
    "plt.plot(k_value,vowel_F1,'-',color='darkgray',label='Vowel')\n",
    "plt.xlabel('k',fontsize=16)\n",
    "plt.ylabel('F1',fontsize=16)\n",
    "#plt.title('F1值曲线图')\n",
    "plt.legend(bbox_to_anchor=(1.05, 0), loc=3, borderaxespad=0)\n",
    "#plt.legend(loc='best',frameon=False)\n",
    "plt.show()\n",
    "#plt.savefig(r'./最优k值结果图/12个数据集3.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fsum=(np.array(iris_F1)+np.array(wine_F1)+np.array(seeds_F1)+np.array(thyroid_F1)+np.array(statlog_F1)+np.array(ecoli_F1)+np.array(glass_F1)+np.array(image_F1)+np.array(letter_F1)+np.array(yeast_F1)+np.array(pen_F1)+np.array(vowel_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=plt.figure(figsize=(6,6))\n",
    "plt.plot(k_value,Fsum,'r-')\n",
    "plt.xlabel('k',fontsize=12)\n",
    "plt.ylabel('Accumulated F1',fontsize=12)\n",
    "plt.xticks([2,4,6,8,10,12,14,16,18,20],['2','4','6','8','10','12','14','16','18','20'])\n",
    "plt.show()\n",
    "#plt.savefig(r'./最优k值结果图/12个数据集fsum3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.106041586968077"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fsum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.09279893, 8.81233294, 8.98439518, 9.04885588, 9.01434263,\n",
       "       9.10604159, 8.794784  , 8.81196952, 8.45650839, 8.4467068 ,\n",
       "       8.34472337, 8.15612902, 8.25393579, 8.14593903, 8.30801232,\n",
       "       8.1873327 , 8.10008762, 8.02625849, 8.0593613 , 8.20909608])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
