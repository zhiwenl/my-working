{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "\n",
    "        knn = self.nearest[:, 1]\n",
    "        belong = []\n",
    "        for i in knn:\n",
    "            belong.append(i.data[-1])\n",
    "        b = max(set(belong), key=belong.count)\n",
    "\n",
    "        return self.nearest, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_sample = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_sample = pd.DataFrame(min_max_scaler.fit_transform(np.array(iris_sample)))\n",
    "iris_sample['label'] = iris.target\n",
    "iris_sample= iris_sample.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data):  \n",
    "    #print('epoch..........:',term)\n",
    "    \n",
    "    Dn,Dn_filted = [],[]\n",
    "    for x in data:\n",
    "        #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "        near, belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        density = 0\n",
    "        t,hon,hen,DRL = 0,0,0,0\n",
    "        for n in near:\n",
    "            if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                t += 1\n",
    "                hon += 1\n",
    "\n",
    "            elif  x[-1] != n[1].data[-1]:\n",
    "                hen += 1\n",
    "\n",
    "            density += n[0]  #密度   \n",
    "\n",
    "        DRL = (hen - hon) / k  #标签异同差比    \n",
    "        Ps = t / k\n",
    "        Pd = 1 - Ps\n",
    "        if (Ps==1)|(Ps==0):\n",
    "            H = 0\n",
    "        else:\n",
    "            H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "\n",
    "       # print(densit)\n",
    "        if (density <= a): #高密度区域\n",
    "           # print('高密度区域')\n",
    "      \n",
    "            if DRL>0:\n",
    "                Dn.append(list(x))\n",
    "              \n",
    "                #print('高密度区域噪声')\n",
    "        else:\n",
    "            if (H < H_): #低密度单一标签区域\n",
    "            \n",
    "                if DRL>0: #再次判断\n",
    "                    Dn.append(list(x))\n",
    "            else: #低密度混合标签区域\n",
    "              #  print('混合区')\n",
    "                data_hon,data_hen=[],[]\n",
    "                for i in data:\n",
    "                    if i[-1]==x[-1]:\n",
    "                        data_hon.append(i)\n",
    "                    else:\n",
    "                        data_hen.append(i)\n",
    "                data_positive=np.array(data_hon)\n",
    "                data_negetive=np.array(data_hen)\n",
    "                kdt_hon=KdTree()\n",
    "                kdt_hen=KdTree()\n",
    "                kdt_hon.create(data_positive)\n",
    "                kdt_hen.create(data_negetive)\n",
    "                near_hon,belong_hon=kdt_hon.search(x[:-1],k+1)\n",
    "                near_hen,belong_hen=kdt_hen.search(x[:-1],k)\n",
    "                dist_hon,dist_hen = 0,0\n",
    "               # print('同类近邻')\n",
    "                for n in near_hon:\n",
    "                    dist_hon += n[0]\n",
    "                    #print(n[1].data,n[0])\n",
    "                #print('异类近邻')\n",
    "                for n in near_hen:\n",
    "                    dist_hen += n[0]\n",
    "                   # print(n[1].data,n[0])\n",
    "                    \n",
    "                if (dist_hon ) / (dist_hen ) > 1.0:\n",
    "                    Dn.append(list(x))\n",
    "                   # print('低密度混合标签区域噪声')  \n",
    "                   # print(x)\n",
    "    noise_neighbor=[]                   \n",
    "    for e in Dn:  # 计算噪声分数\n",
    "        e=np.array(e)\n",
    "        near3,belong3=kdt.search(e[:-1],k+1) #k近邻\n",
    "        for n3 in near3:\n",
    "            noise_neighbor.append(list(n3[1].data))\n",
    "    for e in Dn:\n",
    "        e=np.array(e)\n",
    "        near4,belong4=kdt.search(e[:-1],k+1)\n",
    "        t_e=noise_neighbor.count(list(e))-1 #处于其它噪声近邻的次数\n",
    "        confidence_e= 1 / np.sqrt(1+t_e*t_e)#e的置信度\n",
    "        for i in range(1,k+1):\n",
    "            t_ei=noise_neighbor.count(list(near4[i][1].data))\n",
    "            confidence_ei=1 / np.sqrt(1+t_ei*t_ei) \n",
    "            if near4[i][1].data[-1]==e[-1]:\n",
    "                different_class=-1\n",
    "            else:\n",
    "                different_class=1\n",
    "            if list(near4[i][1].data) in Dn: \n",
    "                isnoise=1\n",
    "            else:\n",
    "                isnoise=-1\n",
    "            near5,belong5=kdt.search(near4[i][1].data[:-1],k+1)\n",
    "            neighborhood_e, dis_neighbor,dis_noise=0,0,0\n",
    "            for j in range(1,k+1):\n",
    "                dis_neighbor += near5[j][0]\n",
    "                if list(near5[j][1].data) in Dn:\n",
    "                    dis_noise +=near5[j][0]\n",
    "            clean_ei= (dis_neighbor + isnoise*(dis_noise-dis_neighbor)) / (2*dis_neighbor) #纯净度\n",
    "            neighborhood_e += (clean_ei*confidence_ei*different_class)/k \n",
    "        NS_e=confidence_e * neighborhood_e #噪声得分\n",
    "        if NS_e > 0:\n",
    "            Dn_filted.append(list(e))\n",
    "                   \n",
    "    #print('标签噪声：',Dn)\n",
    "    noise_list=noise.values.tolist()\n",
    "    TP = 0\n",
    "    for c in Dn_filted:\n",
    "        if c in noise_list:\n",
    "            TP += 1\n",
    "    FP = len(Dn_filted) - TP\n",
    "    FN = len(noise_list) - TP\n",
    "    precision= TP / (TP + FP)\n",
    "    recall= TP / (TP + FN)\n",
    "    fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "    fh= 2*precision*recall / (precision+recall)\n",
    "    re = len(Dn_filted) / len(data)\n",
    "    false_re= FP / len(data)#错误移除比率\n",
    "   # print('准确率:',precision)\n",
    "  #  print('召回率:',recall)\n",
    "   # print('F0.5值:',fh)\n",
    "   # print('移除率:',re)\n",
    "   # print('错误移除率:',false_re)\n",
    "    return fh,re,false_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(data):  \n",
    "    #print('epoch..........:',term)\n",
    "    Dn = []\n",
    "    for x in data:\n",
    "        #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "        near, belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        #print(\"test:\")\n",
    "       # print(x, \"predict:\", belong)\n",
    "       # print(\"nearest:\")\n",
    "        density = 0\n",
    "        t,hon,hen,dist_hon,dist_hen,DoD,DRL= 0,0,0,0,0,0,0\n",
    "        for n in near:\n",
    "            if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                t += 1\n",
    "                hon += 1\n",
    "                dist_hon += n[0]\n",
    "\n",
    "            elif  x[-1] != n[1].data[-1]:\n",
    "                hen += 1\n",
    "                dist_hen += n[0]\n",
    "\n",
    "            density += n[0]  #密度   \n",
    "\n",
    "        DoD = abs(dist_hen - dist_hon) #相异性差值(要加绝对值)\n",
    "        DRL = (hen - hon) / k  #标签异同差比    \n",
    "        Ps = t / k\n",
    "        Pd = 1 - Ps\n",
    "        if (Ps==1)|(Ps==0):\n",
    "            H = 0\n",
    "        else:\n",
    "            H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "      #  print('densit:',density)\n",
    "       \n",
    "        if (density <= a): #高密度区域\n",
    "            print('高密度区域')\n",
    "            if DRL > 0:\n",
    "                Dn.append(list(x))\n",
    "              \n",
    "                #print('高密度区噪声')\n",
    "        else:\n",
    "            if (H < H_): #低密度单一标签区域\n",
    "                if DRL > 0:\n",
    "                    Dn.append(list(x))\n",
    "                 \n",
    "                #    print('低密度单一标签噪声')\n",
    "            else: #低密度混合标签区  \n",
    "        \n",
    "             #   print('低密度混合区')\n",
    "                DoD_ =  density / k\n",
    "               # print('DoD阈值:',DoD_)\n",
    "                if DoD >= DoD_:\n",
    "                    hon_sa,hen_sa,DRL_sa=0,0,0\n",
    "                    near2=[]\n",
    "                    for n in near:\n",
    "                        if n[0] <= a: #该点到待测点距离小于a\n",
    "                            near2.append(n)\n",
    "                    for n2 in near2:\n",
    "                        if (x[-1]==n2[1].data[-1])and (x != n2[1].data).any():\n",
    "                            hon_sa +=1\n",
    "                        elif x[-1] !=n2[1].data[-1]:\n",
    "                            hen_sa +=1\n",
    "                    DRL_sa = hen_sa - hon_sa\n",
    "                    if DRL_sa > 0:        \n",
    "                        Dn.append(list(x))\n",
    "                      #  print('低密度混合标签区噪声')\n",
    "                       # print(x)\n",
    "\n",
    "                    elif DRL_sa ==0 and x[-1] != near[len(near2)][1].data[-1]:\n",
    "                        Dn.append(list(x))    \n",
    "                       # print('低密度混合标签区噪声')\n",
    "                       # print(x)               \n",
    "    noise_list=noise.values.tolist()\n",
    "    TP = 0\n",
    "    for c in Dn:\n",
    "        if c in noise_list:\n",
    "            TP += 1\n",
    "    FP = len(Dn) - TP\n",
    "    FN = len(noise_list) - TP\n",
    "    precision= TP / (TP + FP)\n",
    "    recall= TP / (TP + FN)\n",
    "    fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "    #fh= 2*precision*recall / (precision+recall)\n",
    "    re = len(Dn) / len(data) #移除率\n",
    "    false_re= FP / len(data)\n",
    "    #print('准确率:',precision)\n",
    "    #print('召回率:',recall)\n",
    "    #pri#t('F0.5值:',fh)\n",
    "    #print('移除率:',re)\n",
    "   # print('错误移除率:',false_re)\n",
    "    return fh,re,false_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a值： 1.1758578432296467\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "高密度区域\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df=iris_sample\n",
    "data2=np.array(df.drop('label',axis=1))\n",
    "dist2=[]\n",
    "for m in range(0,len(data2)-1):\n",
    "    for n in range(m+1,len(data2)):\n",
    "        dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "dist2.sort(reverse=True)\n",
    "dist2=np.array(dist2)\n",
    "location= (len(dist2) - 1) * 0.1\n",
    "zhenshu=int(location) #整数部分\n",
    "xiaoshu=(round(location,1)-zhenshu) #小数部分\n",
    "a = (1-xiaoshu)*dist2[zhenshu] + xiaoshu*dist2[zhenshu+1]#密度阈值(%k分位数)\n",
    "print('a值：',a)\n",
    "#a = np.percentile(dist2,10) #密度阈值(%10分位数)\n",
    "k=7\n",
    "x1 = np.array([[1,1],[1,-1]])\n",
    "x2 = np.array([1,np.floor(k / 3)/ k])\n",
    "(Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "\n",
    "F_list,Re_list,F_list2,Re_list2,Fre_list,Fre_list2=[],[],[],[],[],[]\n",
    "#for rate in[0.05,0.1,0.2,0.3,0.4]:\n",
    "for rate in [0.4]:\n",
    "    Fh,Re,Fh2,Re2,false_re,false_re2=[],[],[],[],[],[]\n",
    "    for term in range(1): #多次试验取均值\n",
    "\n",
    "        noise_set=pd.DataFrame(columns=df.columns)\n",
    "        for r in range(0,(df.label.max()+1)):    \n",
    "            noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False,random_state=42)]) #选取噪声比例  \n",
    "        #bb=df[df.label==1].sample(frac=rate, replace=False) #选取噪声比例\n",
    "        #cc=df[df.label==2].sample(frac=rate, replace=False) #选取噪声比例\n",
    "\n",
    "        data_cut=df[~df.index.isin(noise_set.index)]\n",
    "        no=[]\n",
    "        for j in range(0,len(noise_set)):\n",
    "            no.append(int(np.random.rand(1)[0]*(df.label.max()+1))%10)\n",
    "        noise_set['label2']=no\n",
    "        noise_set.reset_index(drop=True,inplace=True)\n",
    "        for l in range(0,len(noise_set)):  #随机替换标签\n",
    "            label_set=list(set(df.label))\n",
    "            if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "                label_set.remove(noise_set.loc[l,'label'])\n",
    "                noise_set.loc[l,'label2']=np.random.choice(label_set) #从剩余列表中随机选择\n",
    "        noise=noise_set.drop(['label'],axis=1)\n",
    "        noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "        data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "        data=np.array(data)\n",
    "        kdt = KdTree()\n",
    "        kdt.create(data)\n",
    "        \n",
    "        result=run(data)\n",
    "        result2=run2(data)\n",
    "        Fh.append(result[0])\n",
    "        Re.append(result[1])\n",
    "        Fh2.append(result2[0])\n",
    "        Re2.append(result2[1])\n",
    "        false_re.append(result[2])\n",
    "        false_re2.append(result2[2])\n",
    "    F_list.append(np.mean(Fh))\n",
    "    Re_list.append(np.mean(Re))\n",
    "    Fre_list.append(np.mean(false_re))\n",
    "    F_list2.append(np.mean(Fh2))\n",
    "    Re_list2.append(np.mean(Re2))\n",
    "    Fre_list2.append(np.mean(false_re2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run(np.array(noise))  1.1758578432296467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run2(np.array(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import mpl_toolkits.axisartist.axislines as axislines\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-6f4894fd9c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFre_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ro-'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'IM_DDF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFre_list2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b*-.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DDF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'噪声比例/%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3358\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3359\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 242\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (1,)"
     ]
    }
   ],
   "source": [
    "noise_rate=[5,10,20,30,40]\n",
    "fig = plt.figure(figsize=(6,14))\n",
    "ax1 = axislines.Subplot(fig, 2,1,1)\n",
    "fig.add_subplot(ax1)\n",
    "ax1.set_xticks(noise_rate)\n",
    "ax1.axis([0,40,0,0.4])\n",
    "plt.plot(noise_rate,Fre_list,'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,Fre_list2,'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "#plt.ylabel('F0.5')\n",
    "plt.ylabel('false_re')\n",
    "#plt.title('不同噪声下F0.5值',fontsize=12)\n",
    "#plt.title('(image)不同噪声下错误移除比例',fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "ax2 = axislines.Subplot(fig, 2,1,2)\n",
    "fig.add_subplot(ax2)\n",
    "ax2.set_xticks([5,10,20,30,40])\n",
    "ax2.set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "ax2.axis([0,40,0,1])\n",
    "plt.plot(noise_rate,Re_list,'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,Re_list2,'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "#plt.ylabel('Re')\n",
    "#plt.title('不同噪声下的过滤值Re',fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout(6) #设置子图间隔\n",
    "plt.suptitle('(Iris)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Re_list,Re_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_list,F_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
