{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "\n",
    "        knn = self.nearest[:, 1]\n",
    "        belong = []\n",
    "        for i in knn:\n",
    "            belong.append(i.data[-1])\n",
    "        b = max(set(belong), key=belong.count)\n",
    "\n",
    "        return self.nearest, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "from sklearn.datasets import load_iris\n",
    "image=pd.read_csv('./mydata/image.csv')\n",
    "image_sample=image.drop(['label'],axis=1)\n",
    "image_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(image_sample)))\n",
    "image_sample['label']=image.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(data):  \n",
    "\n",
    "        # kdt.preOrder(kdt.KdTree)\n",
    "\n",
    "    #print('epoch..........:',term)\n",
    "    \n",
    "    Dn = []\n",
    "    for x in data:\n",
    "        #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "        near, belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        #print(\"test:\")\n",
    "       # print(x, \"predict:\", belong)\n",
    "       # print(\"nearest:\")\n",
    "        density = 0\n",
    "        t,hon,hen,DRL = 0,0,0,0\n",
    "        for n in near:\n",
    "            if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                t += 1\n",
    "                hon += 1\n",
    "\n",
    "            elif  x[-1] != n[1].data[-1]:\n",
    "                hen += 1\n",
    "\n",
    "            density += n[0]  #密度   \n",
    "\n",
    "        DRL = (hen - hon) / k  #标签异同差比    \n",
    "        Ps = t / k\n",
    "        Pd = 1 - Ps\n",
    "        if (Ps==1)|(Ps==0):\n",
    "            H = 0\n",
    "        else:\n",
    "            H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "\n",
    "       # print(densit)\n",
    "        if (density <= a): #高密度区域\n",
    "           # print('高密度区域')\n",
    "           # count+=1\n",
    "           # print('count:',count)\n",
    "            if DRL>0:\n",
    "                Dn.append(list(x))\n",
    "              \n",
    "                #print('高密度区域噪声')\n",
    "        else:\n",
    "            if (H < H_): #低密度单一标签区域\n",
    "            \n",
    "                if DRL>0: #再次判断\n",
    "                    Dn.append(list(x))\n",
    "            else: #低密度混合标签区域\n",
    "              #  print('混合区')\n",
    "                data_hon,data_hen=[],[]\n",
    "                for i in data:\n",
    "                    if i[-1]==x[-1]:\n",
    "                        data_hon.append(i)\n",
    "                    else:\n",
    "                        data_hen.append(i)\n",
    "                data_prositive=np.array(data_hon)\n",
    "                data_negetive=np.array(data_hen)\n",
    "                kdt_hon=KdTree()\n",
    "                kdt_hen=KdTree()\n",
    "                kdt_hon.create(data_prositive)\n",
    "                kdt_hen.create(data_negetive)\n",
    "                near_hon,belong_hon=kdt_hon.search(x[:-1],k+1)\n",
    "                near_hen,belong_hen=kdt_hen.search(x[:-1],k)\n",
    "                dist_hon,dist_hen = 0,0\n",
    "                for n in near_hon:\n",
    "                    dist_hon += n[0]\n",
    "                  #  print(n[1].data)\n",
    "                for n in near_hen:\n",
    "                    dist_hen += n[0]\n",
    "                   # print(n[1].data)\n",
    "                    \n",
    "                if (dist_hon ) / (dist_hen ) > 1.8:\n",
    "                    Dn.append(list(x))\n",
    "                   # print('低密度混合标签区域噪声')  \n",
    "                   # print(x)\n",
    "                   \n",
    "    #print('标签噪声：',Dn)\n",
    "    noise_list=noise.values.tolist()\n",
    "    TP = 0\n",
    "    for c in Dn:\n",
    "        if c in noise_list:\n",
    "            TP += 1\n",
    "    FP = len(Dn) - TP\n",
    "    FN = len(noise_list) - TP\n",
    "    precision= TP / (TP + FP)\n",
    "    recall= TP / (TP + FN)\n",
    "    fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "    fh= 2*precision*recall / (precision+recall)\n",
    "    re = len(Dn) / len(data)\n",
    "    false_re= FP / len(data)#错误移除比率\n",
    "   # print('准确率:',precision)\n",
    "  #  print('召回率:',recall)\n",
    "   # print('F0.5值:',fh)\n",
    "   # print('移除率:',re)\n",
    "    print('错误移除率:',false_re)\n",
    "    return fh,re,false_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(data):  \n",
    "    #print('epoch..........:',term)\n",
    "    Dn = []\n",
    "    for x in data:\n",
    "        #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "        near, belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        #print(\"test:\")\n",
    "       # print(x, \"predict:\", belong)\n",
    "       # print(\"nearest:\")\n",
    "        density = 0\n",
    "        t,hon,hen,dist_hon,dist_hen,DoD,DRL= 0,0,0,0,0,0,0\n",
    "        for n in near:\n",
    "            if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                t += 1\n",
    "                hon += 1\n",
    "                dist_hon += n[0]\n",
    "\n",
    "            elif  x[-1] != n[1].data[-1]:\n",
    "                hen += 1\n",
    "                dist_hen += n[0]\n",
    "\n",
    "            density += n[0]  #密度   \n",
    "\n",
    "        DoD = abs(dist_hen - dist_hon) #相异性差值(要加绝对值)\n",
    "        DRL = (hen - hon) / k  #标签异同差比    \n",
    "        Ps = t / k\n",
    "        Pd = 1 - Ps\n",
    "        if (Ps==1)|(Ps==0):\n",
    "            H = 0\n",
    "        else:\n",
    "            H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "      #  print('densit:',density)\n",
    "       \n",
    "        if (density <= a): #高密度区域\n",
    "            \n",
    "            if DRL > 0:\n",
    "                Dn.append(list(x))\n",
    "              \n",
    "              #  print('高密度区噪声')\n",
    "              #  print(x)\n",
    "              #  for n in near:\n",
    "                #    print(n[1].data,n[0])\n",
    "        else:\n",
    "            if (H < H_): #低密度单一标签区域\n",
    "     \n",
    "                if DRL > 0:\n",
    "                    Dn.append(list(x))\n",
    "                 \n",
    "                #    print('低密度单一标签噪声')\n",
    "         \n",
    "   \n",
    "            else: #低密度混合标签区  \n",
    "        \n",
    "             #   print('低密度混合区')\n",
    "                DoD_ =  density / k\n",
    "               # print('DoD阈值:',DoD_)\n",
    "                if DoD >= DoD_:\n",
    "                    hon_sa,hen_sa,DRL_sa=0,0,0\n",
    "                    near2=[]\n",
    "                    for n in near:\n",
    "                        if n[0] <= a: #该点到待测点距离小于a\n",
    "                            near2.append(n)\n",
    "                    for n2 in near2:\n",
    "                        if (x[-1]==n2[1].data[-1])and (x != n2[1].data).any():\n",
    "                            hon_sa +=1\n",
    "                        elif x[-1] !=n2[1].data[-1]:\n",
    "                            hen_sa +=1\n",
    "                    DRL_sa = hen_sa - hon_sa\n",
    "                    if DRL_sa > 0:        \n",
    "                        Dn.append(list(x))\n",
    "                    \n",
    "                      #  print('低密度混合标签区噪声')\n",
    "                       # print(x)\n",
    "\n",
    "                    elif DRL_sa ==0 and x[-1] != near[len(near2)][1].data[-1]:\n",
    "                        Dn.append(list(x))  \n",
    "                  \n",
    "                       # print('低密度混合标签区噪声')\n",
    "                       # print(x)\n",
    "                        \n",
    "    noise_list=noise.values.tolist()\n",
    "    TP = 0\n",
    "    for c in Dn:\n",
    "        if c in noise_list:\n",
    "            TP += 1\n",
    "    FP = len(Dn) - TP\n",
    "    FN = len(noise_list) - TP\n",
    "    precision= TP / (TP + FP)\n",
    "    recall= TP / (TP + FN)\n",
    "    fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "    #fh= 2*precision*recall / (precision+recall)\n",
    "    re = len(Dn) / len(data) #移除率\n",
    "    false_re= FP / len(data)\n",
    "    #print('准确率:',precision)\n",
    "    #print('召回率:',recall)\n",
    "    #pri#t('F0.5值:',fh)\n",
    "    #print('移除率:',re)\n",
    "    print('错误移除率:',false_re)\n",
    "    return fh,re,false_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.12857142857142856\n",
      "错误移除率: 0.15714285714285714\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.1619047619047619\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.15714285714285714\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.1619047619047619\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.1523809523809524\n",
      "错误移除率: 0.12857142857142856\n",
      "错误移除率: 0.15714285714285714\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.15714285714285714\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.1619047619047619\n",
      "错误移除率: 0.12857142857142856\n",
      "错误移除率: 0.15714285714285714\n",
      "错误移除率: 0.10952380952380952\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.11428571428571428\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.12857142857142856\n",
      "错误移除率: 0.18095238095238095\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.17142857142857143\n",
      "错误移除率: 0.12857142857142856\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.11904761904761904\n",
      "错误移除率: 0.17142857142857143\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.11428571428571428\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.1380952380952381\n",
      "错误移除率: 0.18095238095238095\n",
      "错误移除率: 0.12380952380952381\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.19047619047619047\n",
      "错误移除率: 0.14761904761904762\n",
      "错误移除率: 0.18571428571428572\n",
      "错误移除率: 0.1380952380952381\n",
      "错误移除率: 0.19047619047619047\n",
      "错误移除率: 0.1380952380952381\n",
      "错误移除率: 0.19047619047619047\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.18095238095238095\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.18571428571428572\n",
      "错误移除率: 0.14285714285714285\n",
      "错误移除率: 0.18571428571428572\n",
      "错误移除率: 0.13333333333333333\n",
      "错误移除率: 0.1761904761904762\n",
      "错误移除率: 0.20476190476190476\n",
      "错误移除率: 0.2571428571428571\n",
      "错误移除率: 0.21428571428571427\n",
      "错误移除率: 0.2571428571428571\n",
      "错误移除率: 0.20476190476190476\n",
      "错误移除率: 0.2619047619047619\n",
      "错误移除率: 0.20476190476190476\n",
      "错误移除率: 0.2523809523809524\n",
      "错误移除率: 0.18571428571428572\n",
      "错误移除率: 0.23809523809523808\n",
      "错误移除率: 0.20952380952380953\n",
      "错误移除率: 0.2619047619047619\n",
      "错误移除率: 0.21428571428571427\n",
      "错误移除率: 0.2571428571428571\n",
      "错误移除率: 0.20476190476190476\n",
      "错误移除率: 0.2571428571428571\n",
      "错误移除率: 0.20952380952380953\n",
      "错误移除率: 0.2619047619047619\n",
      "错误移除率: 0.20476190476190476\n",
      "错误移除率: 0.2619047619047619\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df=image_sample\n",
    "data2=np.array(df.drop('label',axis=1))\n",
    "dist2=[]\n",
    "for m in range(0,len(data2)-1):\n",
    "    for n in range(m+1,len(data2)):\n",
    "        dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "a = np.percentile(dist2,10) #密度阈值(%10分位数)\n",
    "k=7\n",
    "x1 = np.array([[1,1],[1,-1]])\n",
    "x2 = np.array([1,np.floor(k / 3)/ k])\n",
    "(Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "\n",
    "F_list,Re_list,F_list2,Re_list2,Fre_list,Fre_list2=[],[],[],[],[],[]\n",
    "for rate in[0.05,0.1,0.2,0.3,0.4]:\n",
    "#for rate in [0.4]:\n",
    "    Fh,Re,Fh2,Re2,false_re,false_re2=[],[],[],[],[],[]\n",
    "    for term in range(10): #多次试验取均值\n",
    "\n",
    "        noise_set=pd.DataFrame(columns=df.columns)\n",
    "        for r in range(0,(df.label.max()+1)):    \n",
    "            noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False,random_state=42)]) #选取噪声比例  \n",
    "        #bb=df[df.label==1].sample(frac=rate, replace=False) #选取噪声比例\n",
    "        #cc=df[df.label==2].sample(frac=rate, replace=False) #选取噪声比例\n",
    "\n",
    "        data_cut=df[~df.index.isin(noise_set.index)]\n",
    "        no=[]\n",
    "        for j in range(0,len(noise_set)):\n",
    "            no.append(int(np.random.rand(1)[0]*(df.label.max()+1))%10)\n",
    "        noise_set['label2']=no\n",
    "        noise_set.reset_index(drop=True,inplace=True)\n",
    "        for l in range(0,len(noise_set)):  #随机替换标签\n",
    "            label_set=list(set(df.label))\n",
    "            if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "                label_set.remove(noise_set.loc[l,'label'])\n",
    "                noise_set.loc[l,'label2']=np.random.choice(label_set) #从剩余列表中随机选择\n",
    "        noise=noise_set.drop(['label'],axis=1)\n",
    "        noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "        data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "        data=np.array(data)\n",
    "        kdt = KdTree()\n",
    "        kdt.create(data)\n",
    "        \n",
    "        result=run(data)\n",
    "        result2=run2(data)\n",
    "        Fh.append(result[0])\n",
    "        Re.append(result[1])\n",
    "        Fh2.append(result2[0])\n",
    "        Re2.append(result2[1])\n",
    "        false_re.append(result[2])\n",
    "        false_re2.append(result2[2])\n",
    "    F_list.append(np.mean(Fh))\n",
    "    Re_list.append(np.mean(Re))\n",
    "    Fre_list.append(np.mean(false_re))\n",
    "    F_list2.append(np.mean(Fh2))\n",
    "    Re_list2.append(np.mean(Re2))\n",
    "    Fre_list2.append(np.mean(false_re2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run(np.array(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run2(np.array(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import mpl_toolkits.axisartist.axislines as axislines\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nax2 = axislines.Subplot(fig, 2,1,2)\\nfig.add_subplot(ax2)\\nax2.set_xticks([5,10,20,30,40])\\nax2.set_yticks([0,0.2,0.4,0.6,0.8,1])\\nax2.axis([0,40,0,1])\\nplt.plot(noise_rate,Re_list,'ro-',label='IM_DDF')\\nplt.plot(noise_rate,Re_list2,'b*-.',label='DDF')\\nplt.xlabel('噪声比例/%')\\n#plt.ylabel('Re')\\n#plt.title('不同噪声下的过滤值Re',fontsize=12)\\nplt.legend()\\nplt.tight_layout(6) #设置子图间隔\\nplt.suptitle('(Iris)')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_rate=[5,10,20,30,40]\n",
    "fig = plt.figure(figsize=(6,14))\n",
    "ax1 = axislines.Subplot(fig, 2,1,1)\n",
    "fig.add_subplot(ax1)\n",
    "ax1.set_xticks(noise_rate)\n",
    "ax1.axis([0,40,0,0.4])\n",
    "plt.plot(noise_rate,Fre_list,'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,Fre_list2,'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "#plt.ylabel('F0.5')\n",
    "plt.ylabel('false_re')\n",
    "#plt.title('不同噪声下F0.5值',fontsize=12)\n",
    "plt.title('(image)不同噪声下错误移除比例',fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "ax2 = axislines.Subplot(fig, 2,1,2)\n",
    "fig.add_subplot(ax2)\n",
    "ax2.set_xticks([5,10,20,30,40])\n",
    "ax2.set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "ax2.axis([0,40,0,1])\n",
    "plt.plot(noise_rate,Re_list,'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,Re_list2,'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "#plt.ylabel('Re')\n",
    "#plt.title('不同噪声下的过滤值Re',fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout(6) #设置子图间隔\n",
    "plt.suptitle('(Iris)')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.18761904761904763,\n",
       "  0.22666666666666666,\n",
       "  0.3176190476190476,\n",
       "  0.4276190476190477,\n",
       "  0.5995238095238096],\n",
       " [0.21142857142857144,\n",
       "  0.2571428571428571,\n",
       "  0.3742857142857143,\n",
       "  0.47619047619047616,\n",
       "  0.6547619047619048])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Re_list,Re_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5243885394828791,\n",
       "  0.6124331030270642,\n",
       "  0.7599524843450076,\n",
       "  0.7984171357903155,\n",
       "  0.7880036696770392],\n",
       " [0.36538252848616387,\n",
       "  0.4431402875993264,\n",
       "  0.5850219360540352,\n",
       "  0.6620154161175273,\n",
       "  0.6593572692541396])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_list,F_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
