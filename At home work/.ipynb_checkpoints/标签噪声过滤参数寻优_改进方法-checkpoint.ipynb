{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "\n",
    "        knn = self.nearest[:, 1]\n",
    "        belong = []\n",
    "        for i in knn:\n",
    "            belong.append(i.data[-1])\n",
    "        b = max(set(belong), key=belong.count)\n",
    "\n",
    "        return self.nearest, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits.axisartist.axislines as axislines\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def run(df):\n",
    "    rate=0.1\n",
    "    noise_set=pd.DataFrame(columns=df.columns)\n",
    "    for r in range(0,(df.label.max()+1)):    \n",
    "        noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False)]) #选取噪声比例 \n",
    "    data_cut=df[~df.index.isin(noise_set.index)]\n",
    "    no=[]\n",
    "    for j in range(0,len(noise_set)):\n",
    "        no.append(int(np.random.rand(1)[0]*(df.label.max()+1))%10)\n",
    "    noise_set['label2']=no\n",
    "    noise_set.reset_index(drop=True,inplace=True)\n",
    "    for l in range(0,len(noise_set)):  #随机替换标签\n",
    "        label_set=list(set(df.label))\n",
    "        if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "            label_set.remove(noise_set.loc[l,'label'])\n",
    "            noise_set.loc[l,'label2']=np.random.choice(label_set) #从剩余列表中随机选择\n",
    "    noise=noise_set.drop(['label'],axis=1)\n",
    "    noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "    data_new= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "\n",
    "    data_new=np.array(data_new)\n",
    "    kdt = KdTree()\n",
    "    kdt.create(data_new)\n",
    "    # kdt.preOrder(kdt.KdTree)\n",
    "    dist2=[]\n",
    "    data2=np.array(df.drop('label',axis=1))\n",
    "    for m in range(0,len(data2)):\n",
    "        for n in range(m+1,len(data2)):\n",
    "             dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "    F1 = []\n",
    "    for d in range(1,61):\n",
    "        a = np.percentile(dist2,d) #密度阈值(%k分位数)\n",
    "        #print('a值：',d)\n",
    "\n",
    "        temp=[]\n",
    "        for k in range(1,61):\n",
    "            #print('k值：',k)\n",
    "            x1 = np.array([[1,1],[1,-1]])\n",
    "            x2 = np.array([1,np.floor(k / 3)/ k])\n",
    "            (Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "            H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "\n",
    "            Dn = []\n",
    "            for x in data_new:\n",
    "                #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "                near, belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        #print(\"test:\")\n",
    "       # print(x, \"predict:\", belong)\n",
    "       # print(\"nearest:\")\n",
    "                density = 0\n",
    "                t,hon,hen,dist_hon,dist_hen,DoD,DRL= 0,0,0,0,0,0,0\n",
    "                for n in near:\n",
    "                    if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                        t += 1\n",
    "                        hon += 1\n",
    "                        dist_hon += n[0]\n",
    "\n",
    "                    elif  x[-1] != n[1].data[-1]:\n",
    "                        hen += 1\n",
    "                        dist_hen += n[0]\n",
    "\n",
    "                    density += n[0]  #密度   \n",
    "\n",
    "                DoD = abs(dist_hen - dist_hon) #相异性差值(要加绝对值)\n",
    "                DRL = (hen - hon) / k  #标签异同差比    \n",
    "                Ps = t / k\n",
    "                Pd = 1 - Ps\n",
    "                if (Ps==1)|(Ps==0):\n",
    "                    H = 0\n",
    "                else:\n",
    "                    H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "              #  print('densit:',density)\n",
    "\n",
    "                if (density <= a): #高密度区域\n",
    "\n",
    "                    if DRL > 0:\n",
    "                        Dn.append(list(x))   \n",
    "                else:\n",
    "                    if (H < H_): #低密度单一标签区域\n",
    "\n",
    "                        if DRL > 0:\n",
    "                            Dn.append(list(x))\n",
    "\n",
    "                        #    print('低密度单一标签噪声')\n",
    "\n",
    "                    else: #低密度混合标签区域\n",
    "                        data_hon,data_hen=[],[]\n",
    "                        for j in data_new:\n",
    "                            if j[-1]==x[-1]:\n",
    "                                data_hon.append(j)\n",
    "                            else:\n",
    "                                data_hen.append(j)\n",
    "                        data_prositive=np.array(data_hon)\n",
    "                        data_negetive=np.array(data_hen)\n",
    "                        kdt_hon=KdTree()\n",
    "                        kdt_hen=KdTree()\n",
    "                        kdt_hon.create(data_prositive)\n",
    "                        kdt_hen.create(data_negetive)\n",
    "                        near_hon,belong_hon=kdt_hon.search(x[:-1],k+1)\n",
    "                        near_hen,belong_hen=kdt_hen.search(x[:-1],k)\n",
    "                        dist_hon,dist_hen = 0,0\n",
    "                        for n in near_hon:\n",
    "                            dist_hon += n[0]\n",
    "                          #  print(n[1].data)\n",
    "                        for n in near_hen:\n",
    "                            dist_hen += n[0]\n",
    "                           # print(n[1].data)\n",
    "\n",
    "                        if (dist_hon ) / (dist_hen ) > 1.3:\n",
    "                            Dn.append(list(x))\n",
    "                           # print('低密度混合标签区域噪声')  \n",
    "                           # print(x)                  \n",
    "            #print('标签噪声：',Dn)\n",
    "            noise_list=noise.values.tolist()\n",
    "            TP = 0\n",
    "            for c in Dn:\n",
    "                if c in noise_list:\n",
    "                    TP += 1\n",
    "            FP = len(Dn) - TP\n",
    "            FN = len(noise_list) - TP\n",
    "            precision= TP / (TP + FP)\n",
    "            recall= TP / (TP + FN)\n",
    "            f1=2 * (precision * recall) / (precision + recall)\n",
    "            temp.append(f1) #F1值\n",
    "        F1.append(temp)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fscore(F_score,title):\n",
    "    F_source=pd.DataFrame(F_score)\n",
    "    f, ax = plt.subplots(figsize=(6,6))\n",
    "#cmap = sns.cubehelix_palette(start = 1.5, rot = 3, gamma=0.8, as_cmap = True)\n",
    "    h=sns.heatmap(F_source, linewidths = 0.01, ax=ax,cbar=False)\n",
    "    font = {'family' : 'serif',\n",
    "            'color'  : 'darkred',\n",
    "            'weight' : 'normal',\n",
    "            'size'   : 16,\n",
    "            }\n",
    "    cb=h.figure.colorbar(h.collections[0])\n",
    "    cb.ax.tick_params(labelsize=12)#设置色标刻度字体大小\n",
    "    cb.set_label('F1',fontdict=font)\n",
    "    ax.set_title(title,fontsize=20)\n",
    "    ax.set_xlabel('k',fontsize=20)\n",
    "    ax.set_ylabel('a',fontsize=20)\n",
    "    ax.axis([0,60,0,60])\n",
    "    plt.xticks([0,20,40,60],['0','20','40','60'],fontsize=12)                         \n",
    "    plt.yticks([20,40,60],['20','40','60'],fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#鸢尾花数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_sample= pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_sample['label'] = iris.target\n",
    "iris_sample=iris_sample.drop_duplicates()\n",
    "iris_F1=run(iris_sample)\n",
    "plot_fscore(iris_F1,'(a)Iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#红酒数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.datasets import load_wine\n",
    "wine= load_wine()\n",
    "wine_sample = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_sample = pd.DataFrame(min_max_scaler.fit_transform(np.array(wine_sample)))\n",
    "wine_sample['label'] = wine.target\n",
    "wine_F1=run(wine_sample)\n",
    "plot_fscore(wine_F1,'(b)Wine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#种子数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds=pd.read_table('./mydata/Seed.txt',engine='python')\n",
    "seeds.columns=(['area','perimeter','compactness','length of kernel','width of kernel','asymmetry coefficient','length of kernel groove','label'])\n",
    "seeds_sample=seeds[['area','perimeter','compactness','length of kernel','width of kernel','asymmetry coefficient','length of kernel groove']]\n",
    "seeds_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(seeds_sample)))\n",
    "seeds_sample['label']=seeds.label\n",
    "seeds_F1=run(seeds_sample)\n",
    "plot_fscore(seeds_F1,'(c)Seeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#玻璃数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "glass=pd.read_csv('./mydata/glass.csv')\n",
    "glass_sample=glass.drop(['label'],axis=1)\n",
    "glass_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(glass_sample)))\n",
    "glass_sample['label']=glass.label\n",
    "glass_F1=run(glass_sample)\n",
    "plot_fscore(glass_F1,'(d)Glass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#蛋白质定位点数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ecoli=pd.read_csv('./mydata/ecoli.csv')\n",
    "ecoli_F1=run(ecoli)\n",
    "plot_fscore(ecoli_F1,'(e)Ecoli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#图像分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image=pd.read_csv('./mydata/image.csv')\n",
    "image_sample=image.drop(['label'],axis=1)\n",
    "image_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(image_sample)))\n",
    "image_sample['label']=image.label\n",
    "image_F1=run(image_sample)\n",
    "plot_fscore(image_F1,'(f)Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#鲍鱼数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ablone=pd.read_csv('./mydata/ablone2.csv')\n",
    "ablone_sample=ablone[['1','2','3','4','5','6','7','8']]\n",
    "ablone_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(ablone_sample)))\n",
    "ablone_sample['label']=ablone.label\n",
    "ablone_F1=run(ablone_sample)\n",
    "plot_fscore(ablone_F1,'(g)Ablone')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#汽车数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "statlog=pd.read_csv('./mydata/statlog.csv',engine='python')\n",
    "statlog.drop_duplicates(inplace=True)\n",
    "statlog_sample=statlog[['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']]\n",
    "statlog_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(statlog_sample)))\n",
    "statlog_sample['label']=statlog.label  \n",
    "statlog_F1=run(statlog_sample)\n",
    "plot_fscore(statlog_F1,'(h)Statlog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#避孕方法数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "cmc=pd.read_table('./mydata/contraception.txt',sep=',')\n",
    "cmc.columns=(['wife_age','wife_edu','husband_edu','num_child','wife_religion','wife_work_station','husband_occupation','living_level','media_exposure','label'])\n",
    "cmc.drop_duplicates(inplace=True)#删除重复数据\n",
    "cmc_sample=cmc[['wife_age','wife_edu','husband_edu','num_child','wife_religion','wife_work_station','husband_occupation','living_level','media_exposure']]\n",
    "cmc_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(cmc_sample)))\n",
    "cmc_sample['label']=list(cmc.label-1) # 不加list标签会出错\n",
    "cmc_F1=run(cmc_sample)\n",
    "plot_fscore(cmc_F1,'(i)Contraception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
