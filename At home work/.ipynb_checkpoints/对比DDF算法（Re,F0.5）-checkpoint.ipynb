{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "\n",
    "        knn = self.nearest[:, 1]\n",
    "        belong = []\n",
    "        for i in knn:\n",
    "            belong.append(i.data[-1])\n",
    "        b = max(set(belong), key=belong.count)\n",
    "\n",
    "        return self.nearest, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fh: 0.822865985670872\n",
      "Re: 0.43933333333333335\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits.axisartist.axislines as axislines\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris_sample= pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(iris_sample)))\n",
    "iris_sample['label'] = iris.target\n",
    "df=iris_sample\n",
    "    \n",
    "data2=np.array(df.drop('label',axis=1))\n",
    "dist2=[]\n",
    "for m in range(0,len(data2)-1):\n",
    "    for n in range(m+1,len(data2)):\n",
    "        dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "a = np.percentile(dist2,10) #密度阈值(%10分位数)\n",
    "k=7\n",
    "x1 = np.array([[1,1],[1,-1]])\n",
    "x2 = np.array([1,np.floor(k / 3)/ k])\n",
    "(Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "Fh,Re,Fre=[],[],[]\n",
    "for term in range(10):\n",
    "   \n",
    "    #for rate in [0.05,0.1,0.2,0.3,0.4]:\n",
    "    rate=0.4\n",
    "    Dn= []\n",
    "    noise_set=pd.DataFrame(columns=df.columns)\n",
    "    label_set=list(set(df.label))\n",
    "    for r in label_set:    \n",
    "        noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False)]) #选取噪声比例 \n",
    "    data_cut=df[~df.index.isin(noise_set.index)]\n",
    "    no=[]\n",
    "    for j in range(0,len(noise_set)):\n",
    "        no.append(np.random.choice(label_set))\n",
    "    noise_set['label2']=no\n",
    "    noise_set.reset_index(drop=True,inplace=True)\n",
    "    for l in range(0,len(noise_set)):  #随机替换标签\n",
    "        label_set=list(set(df.label))\n",
    "        if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "            label_set.remove(noise_set.loc[l,'label'])\n",
    "            noise_set.loc[l,'label2']=np.random.choice(label_set) #从剩余列表中随机选择\n",
    "    noise=noise_set.drop(['label'],axis=1)\n",
    "    noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "    data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "    data=np.array(data)\n",
    "   \n",
    "    kdt = KdTree()\n",
    "    kdt.create(data)  \n",
    "    for x in data:\n",
    "    #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "        near,belong = kdt.search(x[:-1], k+1)  # 设置临近点的个数\n",
    "        density = 0\n",
    "        t,hon,hen,dist_hon,dist_hen,DoD,DRL= 0,0,0,0,0,0,0\n",
    "        for n in near:\n",
    "            if x[-1] == n[1].data[-1]:\n",
    "                if (x != n[1].data).any():\n",
    "                    t += 1\n",
    "                    hon += 1\n",
    "                    dist_hon += n[0]\n",
    "            else:\n",
    "                hen += 1\n",
    "                dist_hen += n[0]\n",
    "\n",
    "            density += n[0]  #密度   \n",
    "\n",
    "        DoD = abs(dist_hen - dist_hon) #相异性差值(要加绝对值)\n",
    "        DRL = (hen - hon) / k #标签异同差比    \n",
    "        Ps = t / k\n",
    "        Pd = 1 - Ps\n",
    "        if (Ps==1)|(Ps==0):\n",
    "            H = 0\n",
    "        else:\n",
    "            H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "      #  print('densit:',density)\n",
    "        if (density <= a): #高密度区域\n",
    "            print('高密度区')\n",
    "            if DRL > 0:\n",
    "                Dn.append(list(x))\n",
    "                print('高密度区噪声')\n",
    "\n",
    "        else:\n",
    "            if (H < H_): #低密度单一标签区域\n",
    "\n",
    "                if DRL > 0:\n",
    "                    Dn.append(list(x))\n",
    "                   # print('低密度单一标签噪声')\n",
    "                    #print('H:',H)\n",
    "                   \n",
    "\n",
    "            else: #低密度混合标签区  \n",
    "              #  print('DoD',DoD)\n",
    "                DoD_ = density / k\n",
    "               # print('DoD阈值:',DoD_)\n",
    "                if DoD >= DoD_:\n",
    "                    hon_sa,hen_sa,DRL_sa=0,0,0\n",
    "                    near2=[]\n",
    "                    for n in near:\n",
    "                        if n[0] <= a: #该点到待测点距离小于a\n",
    "                            near2.append(n)\n",
    "                    for n2 in near2:\n",
    "                        if (x[-1]==n2[1].data[-1]):\n",
    "                            if (x != n[1].data).any():\n",
    "                                hon_sa +=1\n",
    "                        else:\n",
    "                            hen_sa +=1\n",
    "                    DRL_sa = hen_sa - hon_sa\n",
    "                    if DRL_sa > 0:        \n",
    "                        Dn.append(list(x))\n",
    "                       # print('混合标签区噪声')\n",
    "                       \n",
    "                        \n",
    "                    elif DRL_sa ==0 and len(near2)<k:\n",
    "                        if x[-1] != near[len(near2)][1].data[-1]:\n",
    "                            Dn.append(list(x))  \n",
    "                       \n",
    "\n",
    "    noise_list=noise.values.tolist()\n",
    "    TP = 0\n",
    "    for c in Dn:\n",
    "        if c in noise_list:\n",
    "            TP += 1\n",
    "    FP = len(Dn) - TP\n",
    "    FN = len(noise_list) - TP\n",
    "    precision= TP / (TP + FP)\n",
    "    recall= TP / (TP + FN)\n",
    "    fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "    re = len(Dn) / len(data) #移除率\n",
    "    # false_re= FP / len(data)#错误移除比率\n",
    "    Fh.append(fh)\n",
    "    Re.append(re)\n",
    "    #Fre.append(false_re)\n",
    "print('Fh:',np.mean(Fh))\n",
    "print('Re:',np.mean(Re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8487654320987654,\n",
       " 0.8035714285714285,\n",
       " 0.8544303797468356,\n",
       " 0.7926829268292684,\n",
       " 0.7379518072289156,\n",
       " 0.7886904761904763,\n",
       " 0.8717105263157895,\n",
       " 0.8223684210526316,\n",
       " 0.8702531645569621,\n",
       " 0.8382352941176472]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
