{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, depth=0, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.depth = depth\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self):\n",
    "        self.KdTree = None\n",
    "        self.n = 0\n",
    "        self.nearest = None\n",
    "\n",
    "    def create(self, dataSet, depth=0):\n",
    "        if len(dataSet) > 0:\n",
    "            m, n = np.shape(dataSet)\n",
    "            self.n = n - 1\n",
    "            axis = depth % self.n\n",
    "            mid = int(m / 2)\n",
    "            dataSetcopy = sorted(dataSet, key=lambda x: x[axis])\n",
    "            node = Node(dataSetcopy[mid], depth)\n",
    "            if depth == 0:\n",
    "                self.KdTree = node\n",
    "            node.lchild = self.create(dataSetcopy[:mid], depth+1)\n",
    "            node.rchild = self.create(dataSetcopy[mid+1:], depth+1)\n",
    "            return node\n",
    "        return None\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node is not None:\n",
    "            print(node.depth, node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, x, count=1):\n",
    "        nearest = []\n",
    "        for i in range(count):\n",
    "            nearest.append([-1, None])\n",
    "        self.nearest = np.array(nearest)\n",
    "\n",
    "        def recurve(node):\n",
    "            if node is not None:\n",
    "                axis = node.depth % self.n\n",
    "                daxis = x[axis] - node.data[axis]\n",
    "                if daxis < 0:\n",
    "                    recurve(node.lchild)\n",
    "                else:\n",
    "                    recurve(node.rchild)\n",
    "\n",
    "                dist = sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(x, node.data)))\n",
    "                for i, d in enumerate(self.nearest):\n",
    "                    if d[0] < 0 or dist < d[0]:\n",
    "                        self.nearest = np.insert(self.nearest, i, [dist, node], axis=0)\n",
    "                        self.nearest = self.nearest[:-1]\n",
    "                        break\n",
    "\n",
    "                n = list(self.nearest[:, 0]).count(-1)\n",
    "                if self.nearest[-n-1, 0] > abs(daxis):\n",
    "                    if daxis < 0:\n",
    "                        recurve(node.rchild)\n",
    "                    else:\n",
    "                        recurve(node.lchild)\n",
    "\n",
    "        recurve(self.KdTree)\n",
    "\n",
    "        knn = self.nearest[:, 1]\n",
    "        belong = []\n",
    "        for i in knn:\n",
    "            belong.append(i.data[-1])\n",
    "        b = max(set(belong), key=belong.count)\n",
    "\n",
    "        return self.nearest, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "\n",
    "def run(df):  \n",
    "    dist2=[]\n",
    "    data2=np.array(df.drop('label',axis=1))\n",
    "    for m in range(0,len(data2)):\n",
    "        for n in range(m+1,len(data2)):\n",
    "             dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "    a = np.percentile(dist2,10) #密度阈值(%10分位数)\n",
    "    x1 = np.array([[1,1],[1,-1]])\n",
    "    x2 = np.array([1,np.floor(7 / 3)/ 7])\n",
    "    (Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "    H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "\n",
    "    F_list,Re_list=[],[]\n",
    "    for rate in[0.05,0.1,0.2,0.3,0.4]:\n",
    "        P,R,Fh,Re=[],[],[],[]\n",
    "        for term in range(10): #多次试验取均值\n",
    "            \n",
    "            noise_set=pd.DataFrame(columns=df.columns)\n",
    "            for r in range(0,(df.label.max()+1)):    \n",
    "                noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False)]) #选取噪声比例  \n",
    "            #bb=df[df.label==1].sample(frac=rate, replace=False) #选取噪声比例\n",
    "            #cc=df[df.label==2].sample(frac=rate, replace=False) #选取噪声比例\n",
    "\n",
    "            data_cut=df[~df.index.isin(noise_set.index)]\n",
    "            no=[]\n",
    "            for j in range(0,len(noise_set)):\n",
    "                no.append(int(np.random.rand(1)[0]*(df.label.max()+1))%10)\n",
    "            noise_set['label2']=no\n",
    "            noise_set.reset_index(drop=True,inplace=True)\n",
    "            for l in range(0,len(noise_set)):  #随机替换标签\n",
    "                if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "                    noise_set.loc[l,'label2']=(noise_set.loc[l,'label']+1) % (df.label.max()+1)\n",
    "            noise=noise_set.drop(['label'],axis=1)\n",
    "            noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "            data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "\n",
    "            data=np.array(data)\n",
    "            kdt = KdTree()\n",
    "            kdt.create(data)\n",
    "            # kdt.preOrder(kdt.KdTree)\n",
    "            \n",
    "            print('epoch..........:',term)\n",
    "            Dn = []\n",
    "            for x in data:\n",
    "                #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "                near, belong = kdt.search(x[:-1], 8)  # 设置临近点的个数\n",
    "                #print(\"test:\")\n",
    "               # print(x, \"predict:\", belong)\n",
    "               # print(\"nearest:\")\n",
    "                density = 0\n",
    "                t = 0\n",
    "                for n in near:\n",
    "                    #print(n[1].data, \"dist:\", n[0])\n",
    "                    #plt.scatter(n[1].data[0], n[1].data[1], c='green', marker='+')  # k个最近邻点\n",
    "                    density += n[0]  #密度\n",
    "                    if (x[-1] == n[1].data[-1])and (x != n[1].data).any():\n",
    "                        t += 1\n",
    "                Ps = t / 7\n",
    "                Pd = 1 - Ps\n",
    "                if (Ps==1)|(Ps==0):\n",
    "                    H = 0\n",
    "                else:\n",
    "                    H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "\n",
    "               # print(densit)\n",
    "                if (density <= a): #高密度区域\n",
    "                    if x[-1] != belong:\n",
    "                        Dn.append(list(x))\n",
    "\n",
    "                        #print('高密度区域噪声')\n",
    "                else:\n",
    "                    if (H < H_): #低密度单一标签区域\n",
    "                        if x[-1] != belong:\n",
    "                            Dn.append(list(x))\n",
    "                           # print('H:',H)\n",
    "                           # print('低密度单一区域噪声')\n",
    "                    else: #低密度混合标签区域\n",
    "                        hon,hen= 0,0\n",
    "                        dist_hon,dist_hen = 0,0\n",
    "                        for n in near:\n",
    "                            if x[-1]==n[1].data[-1]and(x != n[1].data).any():\n",
    "                                hon += 1\n",
    "                                dist_hon += n[0]\n",
    "                            elif x[-1] != n[1].data[-1]:\n",
    "                                hen +=1\n",
    "                                dist_hen += n[0]\n",
    "                        if (dist_hon / hon) / (dist_hen / hen) > 1.2:\n",
    "                            Dn.append(list(x))\n",
    "                           # print('H:',H)\n",
    "                           # print('低密度混合标签区域噪声')\n",
    "\n",
    "            #print('标签噪声：',Dn)\n",
    "            noise_list=noise.values.tolist()\n",
    "            TP = 0\n",
    "            for c in Dn:\n",
    "                if c in noise_list:\n",
    "                    TP += 1\n",
    "            FP = len(Dn) - TP\n",
    "            FN = len(noise_list) - TP\n",
    "            precision= TP / (TP + FP)\n",
    "            recall= TP / (TP + FN)\n",
    "            fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "        P.append(precision) #准确率\n",
    "        R.append(recall)#召回率\n",
    "        Fh.append(fh) # F0.5\n",
    "        Re.append(len(Dn) / len(data)) #移除率\n",
    "        print(rate*100,'%','噪声下:')\n",
    "        print('准确率:',np.mean(P))\n",
    "        print('召回率:',np.mean(R))\n",
    "        print('F0.5值:',np.mean(Fh))\n",
    "        print('移除率:',np.mean(Re))\n",
    "        F_list.append(np.mean(Fh))\n",
    "        Re_list.append(np.mean(Re))\n",
    "    return F_list,Re_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "5.0 % 噪声下:\n",
      "准确率: 0.9732142857142857\n",
      "召回率: 0.990909090909091\n",
      "F0.5值: 0.9767025089605735\n",
      "移除率: 0.051001821493624776\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "10.0 % 噪声下:\n",
      "准确率: 0.9909502262443439\n",
      "召回率: 0.9954545454545455\n",
      "F0.5值: 0.9918478260869564\n",
      "移除率: 0.10063752276867031\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "20.0 % 噪声下:\n",
      "准确率: 0.9455337690631809\n",
      "召回率: 0.9886104783599089\n",
      "F0.5值: 0.9538461538461538\n",
      "移除率: 0.20901639344262296\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "30.0 % 噪声下:\n",
      "准确率: 0.913235294117647\n",
      "召回率: 0.9423368740515933\n",
      "F0.5值: 0.918910920390648\n",
      "移除率: 0.30965391621129323\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "40.0 % 噪声下:\n",
      "准确率: 0.8406593406593407\n",
      "召回率: 0.8712984054669703\n",
      "F0.5值: 0.8466135458167332\n",
      "移除率: 0.4143897996357013\n",
      "Wall time: 55min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "letter=pd.read_csv('./mydata/letter.csv')\n",
    "letter_sample=letter.drop(['label'],axis=1)\n",
    "letter_sample=pd.DataFrame(min_max_scaler.fit_transform(np.array(letter_sample)))\n",
    "letter_sample['label']=letter.label\n",
    "letter_sample=letter_sample.drop_duplicates()\n",
    "result=run(letter_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#原方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run2(df):  \n",
    "    dist2=[]\n",
    "    data2=np.array(df.drop('label',axis=1))\n",
    "    for m in range(0,len(data2)):\n",
    "        for n in range(m+1,len(data2)):\n",
    "             dist2.append(sqrt(sum((data2[m] - data2[n]) ** 2 )))\n",
    "    a = np.percentile(dist2,10) #密度阈值(%10分位数)\n",
    "    x1 = np.array([[1,1],[1,-1]])\n",
    "    x2 = np.array([1,np.floor(7 / 3)/ 7])\n",
    "    (Ps_,Pd_)=np.linalg.solve(x1,x2)\n",
    "    H_ = -Ps_* np.log2(Ps_)-Pd_*np.log2(Pd_) #标签混合程度阈值\n",
    "\n",
    "    F_list,Re_list=[],[]\n",
    "    for rate in[0.05,0.1,0.2,0.3,0.4]:\n",
    "        P,R,Fh,Re=[],[],[],[]\n",
    "        for term in range(10):#多次试验取均值\n",
    "\n",
    "            noise_set=pd.DataFrame(columns=df.columns)\n",
    "            for r in range(0,(df.label.max()+1)):    \n",
    "                noise_set=pd.concat([noise_set,df[df.label==r].sample(frac=rate, replace=False)]) #选取噪声比例  \n",
    "            #bb=df[df.label==1].sample(frac=rate, replace=False) #选取噪声比例\n",
    "            #cc=df[df.label==2].sample(frac=rate, replace=False) #选取噪声比例\n",
    "\n",
    "            data_cut=df[~df.index.isin(noise_set.index)]\n",
    "            no=[]\n",
    "            for j in range(0,len(noise_set)):\n",
    "                no.append(int(np.random.rand(1)[0]*(df.label.max()+1))%10)\n",
    "            noise_set['label2']=no\n",
    "            noise_set.reset_index(drop=True,inplace=True)\n",
    "            for l in range(0,len(noise_set)):  #随机替换标签\n",
    "                if (noise_set.loc[l,'label']==noise_set.loc[l,'label2']):\n",
    "                    noise_set.loc[l,'label2']=(noise_set.loc[l,'label']+1) % (df.label.max()+1)\n",
    "            noise=noise_set.drop(['label'],axis=1)\n",
    "            noise.rename(columns={'label2':'label'}, inplace = True)\n",
    "            data= pd.concat([data_cut,noise],axis=0,ignore_index=True) #含噪声数据集\n",
    "\n",
    "            data=np.array(data)\n",
    "            kdt = KdTree()\n",
    "            kdt.create(data)\n",
    "            # kdt.preOrder(kdt.KdTree)\n",
    "\n",
    "            print('epoch..........:',term)\n",
    "            Dn = []\n",
    "            for x in data:\n",
    "                #plt.scatter(x[0], x[1], c='red', marker='x')  # 测试点\n",
    "                near, belong = kdt.search(x[:-1], 8)  # 设置临近点的个数\n",
    "                #print(\"test:\")\n",
    "               # print(x, \"predict:\", belong)\n",
    "               # print(\"nearest:\")\n",
    "                density = 0\n",
    "                t,hon,hen,dist_hon,dist_hen,DoD,DRL,count = 0,0,0,0,0,0,0,0\n",
    "                for n in near:\n",
    "                    if x[-1] == n[1].data[-1] and (x != n[1].data).any():\n",
    "                        t += 1\n",
    "                        hon += 1\n",
    "                        dist_hon += n[0]\n",
    "\n",
    "                    elif  x[-1] != n[1].data[-1]:\n",
    "                        hen += 1\n",
    "                        dist_hen += n[0]\n",
    "\n",
    "                    density += n[0]  #密度   \n",
    "\n",
    "                DoD = dist_hen - dist_hon #相异性差值\n",
    "                DRL = hen - hon  #标签异同差比    \n",
    "                Ps = t / 7\n",
    "                Pd = 1 - Ps\n",
    "                if (Ps==1)|(Ps==0):\n",
    "                    H = 0\n",
    "                else:\n",
    "                    H = -Ps* np.log2(Ps)-Pd*np.log2(Pd)\n",
    "               # print(densit)\n",
    "                if (density <= a): #高密度区域\n",
    "                    if DRL > 0:\n",
    "                        Dn.append(list(x))\n",
    "\n",
    "                else:\n",
    "                    if (H < H_): #低密度单一标签区域\n",
    "                        if DRL > 0:\n",
    "                            Dn.append(list(x))\n",
    "\n",
    "                    else: #低密度混合标签区   \n",
    "                        if DoD >= (density / 7):\n",
    "                            Sa,hon_sa,hen_sa,DoD_sa=0,0,0,0\n",
    "                            near2=[]\n",
    "                            for n in near:\n",
    "                                Sa += n[0]\n",
    "                                if Sa <= a:\n",
    "                                    near2.append(n)\n",
    "                            for n2 in near2:\n",
    "                                if (x[-1]==n2[1].data[-1])and (x != n2[1].data).any():\n",
    "                                    hon_sa +=1\n",
    "                                elif x[-1] !=n2[1].data[-1]:\n",
    "                                    hen_sa +=1\n",
    "                                DoD_sa = hen_sa - hon_sa\n",
    "                            if DoD_sa > 0:        \n",
    "                                Dn.append(list(x))\n",
    "\n",
    "                            elif DoD_sa == 0 and x[-1] != near[len(near2)][1].data[-1]:\n",
    "                                Dn.append(list(x))  \n",
    "\n",
    "            #print('标签噪声：',Dn)\n",
    "            noise_list=noise.values.tolist()\n",
    "            TP = 0\n",
    "            for c in Dn:\n",
    "                if c in noise_list:\n",
    "                    TP += 1\n",
    "            FP = len(Dn) - TP\n",
    "            FN = len(noise_list) - TP\n",
    "            precision= TP / (TP + FP)\n",
    "            recall= TP / (TP + FN)\n",
    "            fh= 1.25* (precision * recall) / (0.25*precision + recall) #F0.5值\n",
    "        P.append(precision) #准确率\n",
    "        R.append(recall)#召回率\n",
    "        Fh.append(fh) # F0.5\n",
    "        Re.append(len(Dn) / len(data)) #移除率\n",
    "        print(rate*100,'%','噪声下:')\n",
    "        print('准确率:',np.mean(P))\n",
    "        print('召回率:',np.mean(R))\n",
    "        print('F0.5值:',np.mean(Fh))\n",
    "        print('移除率:',np.mean(Re))\n",
    "        F_list.append(np.mean(Fh))\n",
    "        Re_list.append(np.mean(Re))\n",
    "    return F_list,Re_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "5.0 % 噪声下:\n",
      "准确率: 0.990990990990991\n",
      "召回率: 1.0\n",
      "F0.5值: 0.9927797833935019\n",
      "移除率: 0.050546448087431695\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "10.0 % 噪声下:\n",
      "准确率: 0.9821428571428571\n",
      "召回率: 1.0\n",
      "F0.5值: 0.9856630824372761\n",
      "移除率: 0.10200364298724955\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "20.0 % 噪声下:\n",
      "准确率: 0.9552572706935123\n",
      "召回率: 0.9726651480637813\n",
      "F0.5值: 0.958688819039066\n",
      "移除率: 0.20355191256830601\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "30.0 % 噪声下:\n",
      "准确率: 0.9001426533523538\n",
      "召回率: 0.9575113808801214\n",
      "F0.5值: 0.9110597747617671\n",
      "移除率: 0.3192167577413479\n",
      "epoch..........: 0\n",
      "epoch..........: 1\n",
      "epoch..........: 2\n",
      "epoch..........: 3\n",
      "epoch..........: 4\n",
      "epoch..........: 5\n",
      "epoch..........: 6\n",
      "epoch..........: 7\n",
      "epoch..........: 8\n",
      "epoch..........: 9\n",
      "40.0 % 噪声下:\n",
      "准确率: 0.8188259109311741\n",
      "召回率: 0.9214123006833713\n",
      "F0.5值: 0.8374741200828156\n",
      "移除率: 0.44990892531876137\n"
     ]
    }
   ],
   "source": [
    "result2=run2(letter_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9927797833935019,\n",
       "  0.9856630824372761,\n",
       "  0.958688819039066,\n",
       "  0.9110597747617671,\n",
       "  0.8374741200828156],\n",
       " [0.050546448087431695,\n",
       "  0.10200364298724955,\n",
       "  0.20355191256830601,\n",
       "  0.3192167577413479,\n",
       "  0.44990892531876137])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9767025089605735,\n",
       "  0.9918478260869564,\n",
       "  0.9538461538461538,\n",
       "  0.918910920390648,\n",
       "  0.8466135458167332],\n",
       " [0.051001821493624776,\n",
       "  0.10063752276867031,\n",
       "  0.20901639344262296,\n",
       "  0.30965391621129323,\n",
       "  0.4143897996357013])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import mpl_toolkits.axisartist.axislines as axislines\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_rate=[5,10,20,30,40]\n",
    "fig = plt.figure()\n",
    "ax1 = axislines.Subplot(fig, 1,1,1)\n",
    "fig.add_subplot(ax1)\n",
    "ax1.set_xticks(noise_rate)\n",
    "ax1.axis([0,40,0,1])\n",
    "plt.plot(noise_rate,result[0],'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,result2[0],'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "plt.ylabel('F0.5')\n",
    "plt.title('不同噪声下的F0.5值',fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = axislines.Subplot(fig2, 1,1,1)\n",
    "fig2.add_subplot(ax2)\n",
    "ax2.set_xticks([5,10,20,30,40])\n",
    "ax2.set_yticks([0,0.2,0.4,0.6,0.8])\n",
    "ax2.axis([0,40,0,0.8])\n",
    "plt.plot(noise_rate,result[1],'ro-',label='IM_DDF')\n",
    "plt.plot(noise_rate,result2[1],'b*-.',label='DDF')\n",
    "plt.xlabel('噪声比例/%')\n",
    "plt.ylabel('Re')\n",
    "plt.title('不同噪声下的过滤值Re',fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
